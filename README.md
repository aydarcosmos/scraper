# Airflow Data Pipeline with Docker

This project implements a containerized Airflow DAG that scrapes weather and currency exchange rate data from XML feeds and stores the results in a PostgreSQL database.

## ğŸš€ Features

- **Containerized** with Docker and Docker Compose
- **Data Collection**:
  - ğŸŒ¡ï¸ Weather data from `https://forecast.weather.gov/xml/current_obs/KJFK.xml`
  - ğŸ’± Currency exchange rates from `https://www.floatrates.com/daily/usd.xml`
- **Data Processing**:
  - Current temperature in New York (converted to Celsius)
  - USD to CNY exchange rate extraction
- **Data Storage**: PostgreSQL database with proper schema
- **Error Handling**: Comprehensive logging and error handling
- **Scheduling**: Configurable schedule (default: hourly)

## ğŸ› ï¸ Project Structure

```
.
â”œâ”€â”€ dags/                    # Airflow DAG definitions
â”‚   â””â”€â”€ scraping_dag.py      # Main DAG file
â”œâ”€â”€ plugins/                 # Custom Airflow plugins
â”‚   â””â”€â”€ helpers/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ data_processing.py  # Core data processing logic
â”œâ”€â”€ .env                     # Environment variables
â”œâ”€â”€ .gitattributes           # Git configuration
â”œâ”€â”€ .gitignore              # Git ignore rules
â”œâ”€â”€ docker-compose.yml       # Docker Compose configuration
â”œâ”€â”€ Dockerfile              # Custom Airflow image
â”œâ”€â”€ README.md               # This file
â””â”€â”€ setup.py                # Python package configuration
```

## ğŸš€ Quick Start

### Prerequisites

- Docker and Docker Compose installed
- At least 4GB of free memory for the containers

### Running the Project

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd scraper
   ```

2. **Start the services**
   ```bash
   docker compose up airflow-init
   docker compose up
   ```

3. **Access Airflow UI**
   - Open http://localhost:8080 in your browser
   - Default credentials: `admin` / `admin`

4. **Trigger the DAG**
   - In the Airflow UI, find the `scraping_dag`
   - Toggle the DAG to activate it
   - Trigger a manual run using the play button

## ğŸ“Š Database Schema

The data is stored in two PostgreSQL tables:

### `weather_data`
- `id`: SERIAL PRIMARY KEY
- `temperature_c`: DECIMAL(5,2)
- `timestamp`: TIMESTAMP

### `currency_data`
- `id`: SERIAL PRIMARY KEY
- `usd_to_cny`: DECIMAL(10,4)
- `timestamp`: TIMESTAMP

## ğŸ”§ Customization

### Environment Variables
Edit the `.env` file to configure:
- Database credentials
- Airflow settings
- Data sources and destinations

## ğŸ§ª Testing

Run tests with the following commands:

```bash
pip install -r requirements-test.txt
pytest
```

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.
